{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTAgQfX2KC1l",
        "outputId": "3708bbd8-f7db-4a3c-b1fd-795bf5ee3968"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/drive/MyDrive/Periodic_Motion_CV/frames"
      ],
      "metadata": {
        "id": "W9W3U-WHKadS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "# Path to the input video file\n",
        "video_path = '/content/drive/MyDrive/Periodic_Motion_CV/walking.mp4'\n",
        "\n",
        "# Path to the output frames directory\n",
        "output_directory = '/content/drive/MyDrive/Periodic_Motion_CV/frames'\n",
        "\n",
        "# Open the video file\n",
        "video = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Initialize variables\n",
        "frame_count = 0\n",
        "success = True\n",
        "\n",
        "# Iterate through the video frames\n",
        "while success:\n",
        "    # Read the next frame\n",
        "    success, frame = video.read()\n",
        "    \n",
        "    if success:\n",
        "        # Construct the output frame file name\n",
        "        frame_filename = f'frame_{frame_count}.jpg'\n",
        "        \n",
        "        # Save the frame as an image file\n",
        "        frame_path = os.path.join(output_directory, frame_filename)\n",
        "        cv2.imwrite(frame_path, frame)\n",
        "        \n",
        "        # Increment the frame count\n",
        "        frame_count += 1\n",
        "\n",
        "# Release the video file\n",
        "video.release()\n",
        "\n",
        "print(f'Frames extracted: {frame_count}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qS8fS-K9GxN3",
        "outputId": "188a02d3-1770-4aef-a2b1-f5658ad88e90"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frames extracted: 356\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Detect image points of toes on ground plane </h2> "
      ],
      "metadata": {
        "id": "iLHf7QMS9DgZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Detect toe positions on pedestrian blobs</h3> "
      ],
      "metadata": {
        "id": "okh6uEUCSP8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Function to extract pixels, center and the eigenvector from the bounding box\n",
        "def extract_eigenvector(image, bounding_box):\n",
        "    #'bounding_box' is the YOLO-detected bounding box\n",
        "    x, y, w, h = bounding_box\n",
        "    \n",
        "    # Get the shape of the image\n",
        "    height, width, _ = image.shape\n",
        "    # Convert normalized coordinates to pixel coordinates\n",
        "    x = int(x * width)\n",
        "    y = int(y * height)\n",
        "\n",
        "    c=(x,y)\n",
        "\n",
        "    roi = image[y-h/2:y+h/2, x-w/2:x+w/2]\n",
        "    pixels = np.argwhere(roi > 0) + np.array([x, y])\n",
        "\n",
        "    # Compute the mean of the pixel coordinates\n",
        "    mean = np.mean(pixels, axis=0)\n",
        "\n",
        "    # Compute the centered coordinates by subtracting the mean\n",
        "    centered_pixels = pixels - mean\n",
        "\n",
        "    # Compute the covariance matrix\n",
        "    covariance_matrix = np.cov(centered_pixels, rowvar=False)\n",
        "\n",
        "    # Compute the eigenvalues and eigenvectors of the covariance matrix\n",
        "    eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)\n",
        "\n",
        "    # Sort the eigenvalues and eigenvectors in descending order\n",
        "    sorted_indices = np.argsort(eigenvalues)[::-1]\n",
        "    eigenvectors = eigenvectors[:, sorted_indices]\n",
        "\n",
        "    # Access the first eigenvector (e) and its corresponding eigenvalue (v1)\n",
        "    e = eigenvectors[:, 0]\n",
        "\n",
        "    return pixels, c, e"
      ],
      "metadata": {
        "id": "Srl82S6udsoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Obtain the lambda-shaped frames\n",
        "#Obtain the pedestrian blobs from the lambda-shaped frames\n",
        "\n",
        "\n",
        "def detect_toe_positions(image, bounding_box):\n",
        "    toe_positions = []\n",
        "    \n",
        "    pixels, c, e = extract_eigenvector(image, bounding_box)\n",
        "        \n",
        "    # Iterate through each pixel in the blob\n",
        "    min_dot_product = np.inf\n",
        "    optimal_toe_position = None\n",
        "        \n",
        "    for pixel in pixels:\n",
        "        # Calculate the vector from c to the pixel\n",
        "        t = pixel - c\n",
        "        \n",
        "        # Calculate the dot product of e and t\n",
        "        dot_product = np.dot(e, t)\n",
        "            \n",
        "        # Check if the dot product is minimal\n",
        "        if dot_product < min_dot_product:\n",
        "            min_dot_product = dot_product\n",
        "            optimal_toe_position = pixel\n",
        "        elif dot_product == min_dot_product:\n",
        "            # Choose the pixel farthest from the principal axis\n",
        "            if np.linalg.norm(pixel - c) > np.linalg.norm(optimal_toe_position - c):\n",
        "                optimal_toe_position = pixel\n",
        "        \n",
        "    # Append the optimal toe position to the list\n",
        "    toe_positions.append(optimal_toe_position)\n",
        "    \n",
        "    return toe_positions\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "# Assuming you have pedestrian blobs detected and stored in a list called 'pedestrian_blobs'\n",
        "\n",
        "# Call the function to detect toe positions\n",
        "toe_positions = detect_toe_positions(image, bounding_box)\n",
        "\n",
        "# Print the detected toe positions\n",
        "for i, position in enumerate(toe_positions):\n",
        "    print(f\"Toe position for pedestrian {i+1}: {position}\")\n"
      ],
      "metadata": {
        "id": "dAz8T8B9Ac9I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}